# Dataset Documentation

## Overview

This directory contains datasets for fake news detection with adversarial comments. The datasets are organized into two subdirectories: `Seed/` and `Processed/`. The `Generation.py` script generates adversarial comments from seed data using three Large Language Models.

## Directory Structure

### Seed Data (`Seed/`)

The `Seed/` directory contains raw seed data files that serve as the foundation for generating adversarial comments. These files contain original news articles with their labels but without the generated adversarial comments.

**Available seed datasets:**
- `Rumoureval.json`: English-language rumor detection seed data
- `Weibo16.json`: Chinese-language Weibo dataset from 2016 (seed data)
- `Weibo20.json`: Chinese-language Weibo dataset from 2020 (seed data)

**Seed Data Format:**
Each sample in the seed data contains:
- `content`: The original news article text
- `label`: Binary label indicating "real" or "fake"

### Processed Data (`Processed/`)

The `Processed/` directory contains datasets that have been augmented with adversarial comments (rationales) generated using Large Language Models. Each dataset is organized into subdirectories by dataset name.

**Available processed datasets:**
- `rumour/`: English-language rumor detection dataset with adversarial comments
- `Weibo16/`: Chinese-language Weibo dataset from 2016 with adversarial comments
- `Weibo20/`: Chinese-language Weibo dataset from 2020 with adversarial comments

Each processed dataset contains three JSON files:
- `train.json`: Training set (70% of data)
- `val.json`: Validation set (15% of data)
- `test.json`: Test set (15% of data)

## Processed Data Format

Each sample in the processed datasets is a JSON object with the following structure:

```json
{
    "content": "News article text",
    "label": "real" or "fake",
    "rationale_1": "Original benign comment 1",
    "rationale_2": "Original benign comment 2",
    "rationale_3": "Original benign comment 3",
    "rationale_4": "Fact Distortion attack (generated by model 1)",
    "rationale_5": "Fact Distortion attack (generated by model 2)",
    "rationale_6": "Fact Distortion attack (generated by model 3)",
    "rationale_7": "Logical Confusion attack (generated by model 1)",
    "rationale_8": "Logical Confusion attack (generated by model 2)",
    "rationale_9": "Logical Confusion attack (generated by model 3)",
    "rationale_10": "Emotional Manipulation attack (generated by model 1)",
    "rationale_11": "Emotional Manipulation attack (generated by model 2)",
    "rationale_12": "Emotional Manipulation attack (generated by model 3)"
}
```

### Rationale Categories

The adversarial comments (rationales) are organized into groups based on attack mechanisms:

- **Rationales 1-3**: Original benign comments from the seed data
- **Rationales 4-6**: Fact Distortion attacks
  - `rationale_4`: Fact Distortion attack generated by the first model
  - `rationale_5`: Fact Distortion attack generated by the second model
  - `rationale_6`: Fact Distortion attack generated by the third model
- **Rationales 7-9**: Logical Confusion attacks
  - `rationale_7`: Logical Confusion attack generated by the first model
  - `rationale_8`: Logical Confusion attack generated by the second model
  - `rationale_9`: Logical Confusion attack generated by the third model
- **Rationales 10-12**: Emotional Manipulation attacks
  - `rationale_10`: Emotional Manipulation attack generated by the first model
  - `rationale_11`: Emotional Manipulation attack generated by the second model
  - `rationale_12`: Emotional Manipulation attack generated by the third model

### Attack Mechanisms

Based on cognitive psychology principles, the adversarial comments are categorized into three attack mechanisms:

1. **Fact Distortion**: Comments that manipulate factual information, introduce false claims, or distort evidence to mislead the detector
2. **Logical Confusion**: Comments that employ logical fallacies, create confusion through flawed reasoning, or exploit cognitive biases
3. **Emotional Manipulation**: Comments that use emotional appeals, fear-mongering, or sentiment manipulation to influence detection

## Generating Adversarial Comments

The `Generation.py` script generates adversarial comments from seed data using three LLM models following the "understand-then-generate" prompting strategy described in the paper.

### Prerequisites

1. Ensure the three LLM models are downloaded and placed in the `LLM/` directory:
   - `gemma-2-2b-it/`
   - `Mistral-7B-Instruct-v0___3/`
   - `Qwen2.5-32B/`

2. Install required dependencies:
```bash
pip install torch transformers
```

### Usage

Generate adversarial comments for all datasets:
```bash
cd Data
python Generation.py
```

Generate for a specific dataset:
```bash
python Generation.py --dataset Weibo16
```

Process a subset of samples:
```bash
python Generation.py --ratio 0.5  # Process 50% of samples
```

### Generation Process

The script implements the "understand-then-generate" strategy:

1. **Understanding Phase**: For each attack type, the LLM analyzes the news content to identify:
   - For Fact Distortion: Key factual statements, numbers, sources
   - For Logical Confusion: Cause-effect relationships, logical structures
   - For Emotional Manipulation: Emotional elements, fear-inducing content

2. **Generation Phase**: For each attack mechanism (Fact Distortion, Logical Confusion, or Emotional Manipulation), the generation process follows these steps:
   - Each of the three LLM models (Gemma-2-2B-IT, Mistral-7B-Instruct, Qwen2.5-32B) generates 3 candidate adversarial comments
   - From the 3 candidates generated by each model, one comment is selected
   - This results in 3 final comments (one from each model) for each attack type
   
   **Resulting Structure**:
   - **Rationales 4-6**: Three Fact Distortion attacks, each generated by a different model (one selected from each model's 3 candidates)
   - **Rationales 7-9**: Three Logical Confusion attacks, each generated by a different model (one selected from each model's 3 candidates)
   - **Rationales 10-12**: Three Emotional Manipulation attacks, each generated by a different model (one selected from each model's 3 candidates)

3. **Model Assignment**: The three models are used in rotation to ensure diversity in generated comments. Each model contributes one comment per attack type, selected from its own 3 generated candidates.

The generated comments are automatically split into train/val/test sets (70/15/15) and saved in the `Processed/` directory.

## Usage in Training

The processed datasets are ready for training and evaluation. Use the `train.json`, `val.json`, and `test.json` files from the respective dataset directories in `Processed/`.

For data loading, refer to `Src/utils/dataloader.py` which handles the JSON format and tokenization for both content and rationales.
